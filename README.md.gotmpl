{{ template "chart.header" . }}

{{ template "chart.badgesSection" . }}
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/universal-chart)](https://artifacthub.io/packages/search?repo=universal-chart)

{{ template "chart.description" . }}

## Installation

### Using OCI Registry (Recommended)

The chart is available as an OCI artifact in GitHub Container Registry:

```bash
# Install the chart
helm install my-release oci://ghcr.io/okassov/charts/universal --version {{ template "chart.version" . }}

# Install with custom values
helm install my-release oci://ghcr.io/okassov/charts/universal --version {{ template "chart.version" . }} -f values.yaml

# Upgrade
helm upgrade my-release oci://ghcr.io/okassov/charts/universal --version {{ template "chart.version" . }}
```

### Using Helm Pull

```bash
# Download the chart
helm pull oci://ghcr.io/okassov/charts/universal --version {{ template "chart.version" . }}

# Extract and install
tar -xzf universal-{{ template "chart.version" . }}.tgz
helm install my-release ./universal
```

### View on Artifact Hub

Visit [Artifact Hub](https://artifacthub.io/packages/search?repo=universal-chart) for more installation options and documentation.

## CronJob Support

This chart supports creating multiple CronJob resources alongside the main Deployment for scheduled tasks like backups, cleanups, and data processing.

### Features

- **Multiple CronJobs**: Define multiple independent scheduled jobs via `cronjobs[]` array
- **Full Configuration**: Each CronJob has complete control over image, resources, volumes, security, and scheduling
- **Shared ServiceAccount**: CronJobs use the same ServiceAccount as the main Deployment
- **Production-Ready**: Support for concurrency policies, history limits, deadlines, and TTL
- **Independent Execution**: CronJobs run independently without inheriting configuration from the main application

### Quick Start

Add CronJobs to your values:

```yaml
cronjobs:
  - name: backup
    schedule: "0 2 * * *"  # Daily at 2 AM
    image:
      registry: docker.io
      repository: myapp/backup
      tag: v1.0.0
    command: ["backup"]
    resources:
      requests:
        memory: 256Mi
```

### Complete Example

```yaml
cronjobs:
  # Daily backup job
  - name: backup
    schedule: "0 2 * * *"
    concurrencyPolicy: Forbid  # Don't allow concurrent runs
    successfulJobsHistoryLimit: 7
    failedJobsHistoryLimit: 3

    image:
      registry: docker.io
      repository: myapp/backup
      tag: v1.0.0

    command: ["/bin/sh"]
    args: ["-c", "/scripts/backup.sh"]

    env:
      - name: BACKUP_PATH
        value: /data/backups

    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 256Mi

    volumeMounts:
      - name: data
        mountPath: /data
    volumes:
      - name: data
        persistentVolumeClaim:
          claimName: app-data-pvc

    podSecurityContext:
      runAsNonRoot: true
      fsGroup: 1001
    containerSecurityContext:
      runAsUser: 1001
      readOnlyRootFilesystem: true

  # Weekly cleanup job
  - name: cleanup
    schedule: "0 3 * * 0"  # Sunday at 3 AM
    concurrencyPolicy: Forbid

    image:
      registry: docker.io
      repository: myapp/cleanup
      tag: latest

    command: ["cleanup"]
    args: ["--days=30"]

    resources:
      limits:
        memory: 256Mi

  # Frequent processing job
  - name: process-data
    schedule: "*/15 * * * *"  # Every 15 minutes
    concurrencyPolicy: Replace  # Replace old job if still running
    activeDeadlineSeconds: 600  # Kill after 10 minutes

    image:
      registry: docker.io
      repository: myapp/processor
      tag: v2.1.0

    args: ["process", "--batch-size=1000"]

    resources:
      requests:
        cpu: 500m
        memory: 512Mi

    nodeSelector:
      workload-type: batch
```

### Configuration Options

Each CronJob supports:

**Required Parameters:**
- `name`: Unique identifier for the CronJob
- `schedule`: Cron schedule expression
- `image`: Container image (registry, repository, tag)
- `command` or `args`: What to execute

**CronJob Parameters:**
- `concurrencyPolicy`: Allow, Forbid, or Replace (default: Allow)
- `suspend`: Pause scheduling (default: false)
- `successfulJobsHistoryLimit`: Jobs to keep (default: 3)
- `failedJobsHistoryLimit`: Failed jobs to keep (default: 1)
- `startingDeadlineSeconds`: Deadline to start if missed

**Job Parameters:**
- `restartPolicy`: OnFailure or Never (default: OnFailure)
- `backoffLimit`: Retry attempts
- `activeDeadlineSeconds`: Maximum job duration
- `ttlSecondsAfterFinished`: Cleanup delay after completion

**Pod Configuration:**
- `env`, `envFrom`: Environment variables
- `resources`: CPU and memory limits/requests
- `volumes`, `volumeMounts`: Storage configuration
- `podSecurityContext`, `containerSecurityContext`: Security settings
- `nodeSelector`, `tolerations`, `affinity`: Scheduling constraints

### Management Commands

After deployment, manage CronJobs with:

```bash
# List CronJobs
kubectl get cronjobs -n <namespace>

# View recent jobs
kubectl get jobs -n <namespace>

# Check job logs
kubectl logs -n <namespace> -l app.kubernetes.io/component=cronjob-<name>

# Suspend a CronJob
kubectl patch cronjob <name> -p '{"spec":{"suspend":true}}'

# Resume a CronJob
kubectl patch cronjob <name> -p '{"spec":{"suspend":false}}'

# Manually trigger a job
kubectl create job --from=cronjob/<name> manual-run-$(date +%s)
```

### Best Practices

1. **Concurrency Control**: Use `concurrencyPolicy: Forbid` for jobs that shouldn't overlap
2. **Resource Limits**: Always set resources to prevent resource exhaustion
3. **Security Context**: Run with `runAsNonRoot: true` and drop all capabilities
4. **History Limits**: Keep reasonable history for debugging (3-7 successful, 1-3 failed)
5. **Deadlines**: Set `activeDeadlineSeconds` to prevent hanging jobs
6. **Node Selection**: Use `nodeSelector` or `tolerations` for batch workload nodes

## Monitoring and Alerting

This chart supports Prometheus Operator CRDs for metrics collection and custom alerting.

### Prerequisites

- [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack) or Prometheus Operator installed in your cluster
- ServiceMonitor and PrometheusRule CRDs available

### Enabling Metrics Collection

To enable Prometheus metrics scraping via ServiceMonitor:

```yaml
metrics:
  enabled: true
  path: /metrics
  port: ""  # Container port for metrics (optional, defaults to service port)

  service:
    port: 8081  # Service port for metrics endpoint

  serviceMonitor:
    enabled: true
    interval: 30s
    scrapeTimeout: 10s

    # IMPORTANT: Labels must match your Prometheus serviceMonitorSelector
    labels:
      release: prometheus-operator  # Adjust to your Prometheus release name
```

### Creating Custom Alerts

Define custom alerting rules using PrometheusRule CRD:

```yaml
metrics:
  enabled: true

  prometheusRule:
    enabled: true

    # IMPORTANT: Labels must match your Prometheus ruleSelector
    additionalLabels:
      release: prometheus-operator  # Adjust to your Prometheus release name
      role: alert-rules

    # Define multiple rule groups
    groups:
      # Application availability alerts
      - name: application-availability
        interval: 30s
        rules:
          - alert: HighErrorRate
            expr: |
              (
                sum(rate(http_requests_total{status=~"5.."}[5m]))
                /
                sum(rate(http_requests_total[5m]))
              ) > 0.05
            for: 5m
            labels:
              severity: critical
              component: api
            annotations:
              summary: "High HTTP 5xx error rate"
              description: "Error rate is {{`{{ $value | humanizePercentage }}`}} (threshold: 5%)"
              runbook_url: "https://runbooks.example.com/high-error-rate"

          - alert: ServiceDown
            expr: up == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Service is down"
              description: "{{`{{ $labels.instance }}`}} has been down for more than 2 minutes"

      # Performance alerts
      - name: application-performance
        rules:
          - alert: HighLatency
            expr: |
              histogram_quantile(0.95,
                sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
              ) > 1
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "High request latency"
              description: "P95 latency is {{`{{ $value }}`}}s (threshold: 1s)"

      # Business metrics alerts
      - name: business-metrics
        interval: 1m
        rules:
          - alert: LowOrderRate
            expr: rate(orders_total[10m]) < 10
            for: 15m
            labels:
              severity: warning
              team: business
            annotations:
              summary: "Order rate is below threshold"
              description: "Current rate: {{`{{ $value | humanize }}`}} orders/sec"

          # Recording rule example
          - record: job:http_requests:rate5m
            expr: sum(rate(http_requests_total[5m])) by (job)
```

### Important Configuration Notes

#### 1. Label Selectors

For Prometheus Operator to discover your ServiceMonitor and PrometheusRule resources, their labels must match the selectors configured in your Prometheus CR.

**Find your Prometheus selectors:**

```bash
# Check serviceMonitorSelector
kubectl get prometheus -n monitoring -o jsonpath='{.items[0].spec.serviceMonitorSelector}'

# Check ruleSelector
kubectl get prometheus -n monitoring -o jsonpath='{.items[0].spec.ruleSelector}'
```

Common configurations:
- **kube-prometheus-stack**: `release: <your-prometheus-release-name>`
- **prometheus-operator**: `prometheus: kube-prometheus`

#### 2. Rule Group Organization

Organize your alerts into logical groups:
- **application-availability**: Uptime, error rates, health checks
- **application-performance**: Latency, throughput, resource usage
- **business-metrics**: Business KPIs, custom metrics, SLOs

Each group can have its own evaluation `interval`.

#### 3. Alert Severity Levels

Use consistent severity labels:
- `critical`: Requires immediate action, affects users
- `warning`: Should be addressed soon, potential issues
- `info`: Informational, no action required

#### 4. Annotations Best Practices

Include helpful context in annotations:
- `summary`: Short description of the alert
- `description`: Detailed information with templated values
- `runbook_url`: Link to remediation documentation
- `dashboard_url`: Link to relevant Grafana dashboard

### Complete Example

```yaml
metrics:
  enabled: true
  path: /metrics

  service:
    port: 8081

  serviceMonitor:
    enabled: true
    interval: 30s
    labels:
      release: prometheus-operator
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        targetLabel: node

  prometheusRule:
    enabled: true
    additionalLabels:
      release: prometheus-operator
      role: alert-rules
    groups:
      - name: my-app-alerts
        interval: 30s
        rules:
          - alert: HighErrorRate
            expr: rate(http_errors_total[5m]) > 0.05
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "High error rate detected"
              description: "Error rate: {{`{{ $value | humanizePercentage }}`}}"
```

{{ template "chart.requirementsSection" . }}

{{ template "chart.valuesSection" . }}

{{ template "helm-docs.versionFooter" . }}
